{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Final.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhGkdtd2kWfF",
        "colab_type": "text"
      },
      "source": [
        "I orignally ran everything with jupyter lab. My first model was a KNN model with only 10k rows of data and 5000 max features in the vectorizer which was too small for a dataset of 1 million rows. Also tried a random forest classification pipeline with random search for hyper tuning. Both models had their drawbacks in terms of either memory use and accuracy score. I then used paperspace to run a model on their cloud notebook. My final model was a naive bayes classifier which I was about to train with 400k rows of data with 5000 max features on the tf-idfd vectorizer.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3KtqxCjATFx",
        "colab_type": "text"
      },
      "source": [
        "## Tokenizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x8ko2nuAO8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('kaggle_RC_2019-05.csv', engine='python', error_bad_lines=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZdlAqleAO8i",
        "colab_type": "code",
        "outputId": "ce8ffec2-2a5b-4277-f0ee-c7fb9f42834d",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gameofthrones</td>\n",
              "      <td>Your submission has been automatically removed...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aww</td>\n",
              "      <td>Dont squeeze her with you massive hand, you me...</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gaming</td>\n",
              "      <td>It's pretty well known and it was a paid produ...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>news</td>\n",
              "      <td>You know we have laws against that currently c...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>politics</td>\n",
              "      <td>Yes, there is a difference between gentle supp...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       subreddit                                               body  \\\n",
              "0  gameofthrones  Your submission has been automatically removed...   \n",
              "1            aww  Dont squeeze her with you massive hand, you me...   \n",
              "2         gaming  It's pretty well known and it was a paid produ...   \n",
              "3           news  You know we have laws against that currently c...   \n",
              "4       politics  Yes, there is a difference between gentle supp...   \n",
              "\n",
              "   controversiality  score  \n",
              "0                 0      1  \n",
              "1                 0     19  \n",
              "2                 0      3  \n",
              "3                 0     10  \n",
              "4                 0      1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGQiDIKMAO8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using spacy for processing our text data\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = Tokenizer(nlp.vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUlQnM3kAO8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenizer Pipe\n",
        "\n",
        "tokens = []\n",
        "\n",
        "\"\"\" Make them tokens \"\"\"\n",
        "for doc in tokenizer.pipe(df['body'], batch_size=500):\n",
        "    doc_tokens = [token.text for token in doc]\n",
        "    tokens.append(doc_tokens)\n",
        "\n",
        "df['tokens'] = tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZG2pKoskNHd",
        "colab_type": "text"
      },
      "source": [
        "## Using 500,000 rows of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsxE-49VAO8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating my subset data for training and testing\n",
        "subset = df.sample(400000)\n",
        "text = df.sample(100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P2BvuabAO83",
        "colab_type": "code",
        "outputId": "cb3844d3-ca1d-41a5-ab06-8f0aeec151c1",
        "colab": {}
      },
      "source": [
        "# Viewing all subreddits\n",
        "subset.subreddit.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RoastMe                10152\n",
              "unpopularopinion       10141\n",
              "ChapoTrapHouse         10117\n",
              "dankmemes              10095\n",
              "movies                 10095\n",
              "relationship_advice    10085\n",
              "todayilearned          10062\n",
              "FortNiteBR             10058\n",
              "apexlegends            10052\n",
              "teenagers              10051\n",
              "SquaredCircle          10035\n",
              "aww                    10032\n",
              "AmItheAsshole          10027\n",
              "Market76               10023\n",
              "AskReddit              10021\n",
              "hockey                 10020\n",
              "nfl                    10009\n",
              "trashy                 10006\n",
              "gaming                 10005\n",
              "freefolk               10005\n",
              "Pikabu                 10002\n",
              "marvelstudios          10002\n",
              "videos                  9990\n",
              "gonewild                9988\n",
              "worldnews               9987\n",
              "leagueoflegends         9984\n",
              "soccer                  9977\n",
              "gameofthrones           9975\n",
              "nba                     9974\n",
              "MortalKombat            9964\n",
              "wallstreetbets          9960\n",
              "news                    9957\n",
              "asoiaf                  9952\n",
              "funny                   9943\n",
              "Showerthoughts          9928\n",
              "memes                   9921\n",
              "Animemes                9912\n",
              "politics                9900\n",
              "The_Donald              9879\n",
              "pics                    9714\n",
              "Name: subreddit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9xZU0UAO89",
        "colab_type": "code",
        "outputId": "82b49109-eda7-48ea-a3fc-919989d05f02",
        "colab": {}
      },
      "source": [
        "# Importing our vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate vectorizer object\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features=5000)\n",
        "\n",
        "# Create a vocabulary and get word counts per document\n",
        "# Similiar to fit_predict\n",
        "dtm = tfidf.fit_transform(subset.body)\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>08</th>\n",
              "      <th>...</th>\n",
              "      <th>тут</th>\n",
              "      <th>ты</th>\n",
              "      <th>уже</th>\n",
              "      <th>чем</th>\n",
              "      <th>что</th>\n",
              "      <th>чтобы</th>\n",
              "      <th>это</th>\n",
              "      <th>этого</th>\n",
              "      <th>этом</th>\n",
              "      <th>этот</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000   01   02   03   04   05   06   07   08  ...  тут   ты  уже  чем  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   что  чтобы  это  этого  этом  этот  \n",
              "0  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "1  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "2  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "3  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "4  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5402TdMAO9C",
        "colab_type": "code",
        "outputId": "6bff9f56-2201-4ff7-8e42-46e9df960717",
        "colab": {}
      },
      "source": [
        "#fit test data to tf-idf\n",
        "dtm_test = tfidf.fit_transform(text.body)\n",
        "\n",
        "# Get feature names to use as dataframe column headers\n",
        "dtm_test = pd.DataFrame(dtm_test.todense(), columns=tfidf.get_feature_names())\n",
        "\n",
        "# View Feature Matrix as DataFrame\n",
        "dtm_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>039</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>...</th>\n",
              "      <th>тут</th>\n",
              "      <th>ты</th>\n",
              "      <th>уже</th>\n",
              "      <th>чем</th>\n",
              "      <th>что</th>\n",
              "      <th>чтобы</th>\n",
              "      <th>это</th>\n",
              "      <th>этого</th>\n",
              "      <th>этом</th>\n",
              "      <th>этот</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  000   01   02   03  039   04   05   06   07  ...  тут   ты  уже  чем  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
              "\n",
              "   что  чтобы  это  этого  этом  этот  \n",
              "0  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "1  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "2  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "3  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "4  0.0    0.0  0.0    0.0   0.0   0.0  \n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsNwDU9wBK-4",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMKYyqaGAO9G",
        "colab_type": "code",
        "outputId": "ea02a4d4-3196-431e-b85d-39e5a25f2168",
        "colab": {}
      },
      "source": [
        "# Importing naive bayes from sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Instantiating our model\n",
        "naive_bayes = MultinomialNB()\n",
        "\n",
        "# fitting our model with our trained data\n",
        "naive_bayes.fit(dtm, subset.subreddit)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXfmNhn6AO9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict\n",
        "predictions = naive_bayes.predict(dtm_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1CORGphAO9O",
        "colab_type": "code",
        "outputId": "65e26c2c-1739-44d3-e95b-e36bf214257e",
        "colab": {}
      },
      "source": [
        "# Getting our accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy score: ', accuracy_score(text.subreddit, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.06768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cshbcLT7AO9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "filename = \"tfidf.pkl\"\n",
        "pickle.dump(tfidf, open(filename, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-mslbSVAO9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename2 = \"naive_bayes.pkl\"\n",
        "pickle.dump(naive_bayes, open(filename2, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APWrPHAdAO9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset.to_csv(\"data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGfbk0aWAO9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset.to_pickle(\"data.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLLPpCqrAO9n",
        "colab_type": "code",
        "outputId": "90fd6b4a-59bc-4b5f-b570-666282ea79c4",
        "colab": {}
      },
      "source": [
        "dtm.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO6q0oUoAO9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqsVHs9NAO9u",
        "colab_type": "code",
        "outputId": "fd8d63b0-bbd1-4935-9eb4-04002bf23e6d",
        "colab": {}
      },
      "source": [
        "dtm.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>15</th>\n",
              "      <th>20</th>\n",
              "      <th>2019</th>\n",
              "      <th>2FMarket76</th>\n",
              "      <th>2Fr</th>\n",
              "      <th>...</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>yourself</th>\n",
              "      <th>youtube</th>\n",
              "      <th>как</th>\n",
              "      <th>на</th>\n",
              "      <th>не</th>\n",
              "      <th>то</th>\n",
              "      <th>что</th>\n",
              "      <th>это</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   000  10  100  11  12  15  20  2019  2FMarket76  2Fr  ...  young  your  \\\n",
              "0    0   0    0   0   0   0   0     0           0    0  ...      0     3   \n",
              "1    0   0    0   0   0   0   0     0           0    0  ...      0     0   \n",
              "2    0   0    0   0   0   0   0     0           0    0  ...      0     0   \n",
              "3    0   0    0   0   0   0   0     0           0    0  ...      0     0   \n",
              "4    0   0    0   0   0   0   0     0           0    0  ...      0     0   \n",
              "\n",
              "   yourself  youtube  как  на  не  то  что  это  \n",
              "0         1        1    0   0   0   0    0    0  \n",
              "1         0        0    0   0   0   0    0    0  \n",
              "2         0        0    0   0   0   0    0    0  \n",
              "3         0        0    0   0   0   0    0    0  \n",
              "4         0        0    0   0   0   0    0    0  \n",
              "\n",
              "[5 rows x 1000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-rbkrm_Bm6L",
        "colab_type": "text"
      },
      "source": [
        "# K Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbeZ5XL0AO9x",
        "colab_type": "code",
        "outputId": "9fd3407d-e51e-4d57-ae25-e3ec1f72ec23",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Fit on DTM\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwxwMADlAO90",
        "colab_type": "code",
        "outputId": "e3b23220-8dfb-4a69-c375-8d6af7f67632",
        "colab": {}
      },
      "source": [
        "# Query Using kneighbors \n",
        "nn.kneighbors([dtm.iloc[25000]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]]),\n",
              " array([[ 45651, 249566,  25000, 347143,   1140,   3245,   2785,   6893,\n",
              "           3694,   5784]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lXegLGKAO95",
        "colab_type": "code",
        "outputId": "847e6358-93bd-4b37-9372-84286abd7e98",
        "colab": {}
      },
      "source": [
        "subset.iloc[45651]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subreddit                                               SquaredCircle\n",
              "body                    Yaayyyyy!!! Wrestling revolution is amazing!!\n",
              "controversiality                                                    0\n",
              "score                                                              11\n",
              "tokens              [Yaayyyyy!!!, Wrestling, revolution, is, amazi...\n",
              "Name: 784105, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyBd2rX-AO98",
        "colab_type": "code",
        "outputId": "9d9e2193-8749-43f4-8951-7a8273392d22",
        "colab": {}
      },
      "source": [
        "subset.iloc[249566]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subreddit                             FortNiteBR\n",
              "body                     tbh faithful is amazing\n",
              "controversiality                               0\n",
              "score                                         11\n",
              "tokens              [tbh, faithful, is, amazing]\n",
              "Name: 719852, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si96vk50AO9_",
        "colab_type": "code",
        "outputId": "ec4113b1-b959-4bc5-9f9b-3d61de1399a3",
        "colab": {}
      },
      "source": [
        "subset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>body</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>score</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>595340</th>\n",
              "      <td>The_Donald</td>\n",
              "      <td>&amp;gt;It was a desperate hail Mary.\\n\\nAnd Mary ...</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>[&amp;gt;It, was, a, desperate, hail, Mary., \\n\\n,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309314</th>\n",
              "      <td>memes</td>\n",
              "      <td>Happy cake day and true story btw</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>[Happy, cake, day, and, true, story, btw]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588045</th>\n",
              "      <td>hockey</td>\n",
              "      <td>&amp;gt;This was so dangerous\\n\\nWhat?</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[&amp;gt;This, was, so, dangerous, \\n\\n, What?]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320145</th>\n",
              "      <td>trashy</td>\n",
              "      <td>Had a good scoot on these in Lisbon! But... Po...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>[Had, a, good, scoot, on, these, in, Lisbon!, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>875311</th>\n",
              "      <td>RoastMe</td>\n",
              "      <td>ðŸ¦€ ðŸ¦€ contest winners were never sent thei...</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>[ðŸ¦€, ðŸ¦€, contest, winners, were, never, se...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         subreddit                                               body  \\\n",
              "595340  The_Donald  &gt;It was a desperate hail Mary.\\n\\nAnd Mary ...   \n",
              "309314       memes                  Happy cake day and true story btw   \n",
              "588045      hockey                 &gt;This was so dangerous\\n\\nWhat?   \n",
              "320145      trashy  Had a good scoot on these in Lisbon! But... Po...   \n",
              "875311     RoastMe  ðŸ¦€ ðŸ¦€ contest winners were never sent thei...   \n",
              "\n",
              "        controversiality  score  \\\n",
              "595340                 0    112   \n",
              "309314                 0     -1   \n",
              "588045                 0      3   \n",
              "320145                 0     11   \n",
              "875311                 0     39   \n",
              "\n",
              "                                                   tokens  \n",
              "595340  [&gt;It, was, a, desperate, hail, Mary., \\n\\n,...  \n",
              "309314          [Happy, cake, day, and, true, story, btw]  \n",
              "588045        [&gt;This, was, so, dangerous, \\n\\n, What?]  \n",
              "320145  [Had, a, good, scoot, on, these, in, Lisbon!, ...  \n",
              "875311  [ðŸ¦€, ðŸ¦€, contest, winners, were, never, se...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGlvCri0AO-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post = \"\"\"\n",
        "In 1991 I won a contest for a pre-release copy of Dragon Warrior III. It came with a letter hand-signed by everyone at Enix America (now SquareEnix). 15-year-old me was blown away!\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrstVylIAO-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query\n",
        "new = vect.transform([post])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPnKLVkgAO-J",
        "colab_type": "code",
        "outputId": "2e00aa8d-e1e4-4eeb-874d-1aca714af64b",
        "colab": {}
      },
      "source": [
        "nn.kneighbors(new.todense())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[13.3041347 , 13.52774926, 13.52774926, 13.74772708, 13.78404875,\n",
              "         13.85640646, 13.85640646, 13.89244399, 13.92838828, 13.96424004]]),\n",
              " array([[4742, 6136, 9837, 9912, 1627, 1403, 5149, 8837, 1605,  910]],\n",
              "       dtype=int64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYNzDWfvAO-M",
        "colab_type": "code",
        "outputId": "6dd2e277-e23e-485c-c6a0-39707f31d1d7",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nIn 1991 I won a contest for a pre-release copy of Dragon Warrior III. It came with a letter hand-signed by everyone at Enix America (now SquareEnix). 15-year-old me was blown away!\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Ce8n3KBwSv",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest Classification Pipeline / GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRUkTKGIAO-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Statements\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eICryR6WAO-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Pipeline Components\n",
        "\n",
        "vect = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "rfc = RandomForestClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nfBHdOAAO-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the Pipeline\n",
        "pipe = Pipeline([\n",
        "                 #Vectorizer\n",
        "                 ('vect', vect),\n",
        "                 # Classifier\n",
        "                 ('clf', rfc)\n",
        "                ])\n",
        "\n",
        "# The pipeline puts together a bunch fit then transform,fit then predict. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8z5BWFAO-a",
        "colab_type": "code",
        "outputId": "f114c315-c76e-41f3-fa0d-0808bdbfe0f2",
        "colab": {}
      },
      "source": [
        "parameters = {\n",
        "    'vect__max_df': ( 0.75, 1.0),\n",
        "    'vect__min_df': (.02, .05),\n",
        "    'vect__max_features': (500,1000),\n",
        "    'clf__n_estimators':(5, 10,),\n",
        "    'clf__max_depth':(15,20)\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipe,parameters, cv=2, verbose=1)\n",
        "grid_search.fit(subset.body, subset.subreddit)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 32 candidates, totalling 64 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  5.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
              "        ...obs=None,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False))]),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'vect__max_df': (0.75, 1.0), 'vect__min_df': (0.02, 0.05), 'vect__max_features': (500, 1000), 'clf__n_estimators': (5, 10), 'clf__max_depth': (15, 20)},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIiUrj6QAO-d",
        "colab_type": "code",
        "outputId": "095113be-8b55-485b-d48f-986da451ddad",
        "colab": {}
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxYvqFCrAO-i",
        "colab_type": "code",
        "outputId": "6e824db3-f6e1-4ff4-b94f-fb27c646845a",
        "colab": {}
      },
      "source": [
        "grid_search.predict(['In 1991 I won a contest for a pre-release copy of Dragon Warrior III. It came with a letter hand-signed by everyone at Enix America (now SquareEnix). 15-year-old me was blown away!'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['AmItheAsshole'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}